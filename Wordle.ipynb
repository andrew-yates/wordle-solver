{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, random, time\n",
    "import requests, json, re\n",
    "from string import ascii_lowercase\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordle_num = 249\n",
    "answers = []\n",
    "guesses = []\n",
    "BEARER_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in possible answer and guess words\n",
    "with open('answers.txt', 'r') as f:\n",
    "    answers = [x.strip() for x in f.readlines()]\n",
    "with open('guesses.txt', 'r') as f:\n",
    "    guesses = [x.strip() for x in f.readlines()]\n",
    "#Token for twitter API\n",
    "with open(\"bearer_token\", 'r') as f:\n",
    "    BEARER_TOKEN = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the result pattern for a guess and the possible guesses and answers, figure out which answers have a guess which could've resulted in that pattern, and thus could have been the possible answer for the puzzle. Repeat with multiple different guess patterns for a day to narrow down the possible answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to score wordle guess. From https://mathspp.com/blog/solving-wordle-with-python\n",
    "def score(secret, guess):\n",
    "    # All characters that are not correct go into the usable pool.\n",
    "    pool = collections.Counter(s for s, g in zip(secret, guess) if s != g)\n",
    "    # Create a first tentative score by comparing char by char.\n",
    "    score = []\n",
    "    for secret_char, guess_char in zip(secret, guess):\n",
    "        if secret_char == guess_char:\n",
    "            score.append(2)\n",
    "        elif guess_char in secret and pool[guess_char] > 0:\n",
    "            score.append(1)\n",
    "            pool[guess_char] -= 1\n",
    "        else:\n",
    "            score.append(0)\n",
    "    return score\n",
    "#Check if an answer and a guess will make the pattern result\n",
    "def check_fit(answer, guess, result):\n",
    "    return result == score(answer, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes ~1.5 min, creates dicts to speed up narrowing down possibilities for a guess pattern\n",
    "def create_useful_dicts():\n",
    "    pos_letter_answer_dict = {}\n",
    "    #set up position letter dictionary\n",
    "    for i in range(5):\n",
    "        pos_letter_answer_dict[i] = {}\n",
    "        for j in ascii_lowercase:\n",
    "            pos_letter_answer_dict[i][j] = set()\n",
    "    for guess in guesses:\n",
    "        for i, j in enumerate(guess):\n",
    "            pos_letter_answer_dict[i][j].add(guess)\n",
    "\n",
    "    #So I want to have an answer, and then from it get possible guesses. These guesses will be ones that have, at \n",
    "    # index i, a character found anywhere in answer. Not super useful, and big.\n",
    "    any_letter_answer_dict = {}\n",
    "    for answer in answers:\n",
    "        any_letter_answer_dict[answer] = {}\n",
    "        for i in range(5):\n",
    "            any_letter_answer_dict[answer][i] = set()\n",
    "        for guess in guesses:\n",
    "            for i, j in enumerate(guess):\n",
    "                ind = answer.find(j)\n",
    "                if ind != -1 and ind != i:\n",
    "                    any_letter_answer_dict[answer][i].add(guess)\n",
    "    return pos_letter_answer_dict, any_letter_answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to find possible answers for a given result\n",
    "def result_answers_opt(result, answers, guesses, pos_letter_answer_dict, any_letter_answer_dict):\n",
    "    possible_answers = set()\n",
    "    for answer in answers:\n",
    "        #filter guesses based on 2s in the result\n",
    "        filtered_guesses = set(guesses)\n",
    "        for i, x in enumerate(result):\n",
    "            if x == 2:\n",
    "                filtered_guesses = filtered_guesses.intersection(pos_letter_answer_dict[i][answer[i]])\n",
    "            if x == 1:\n",
    "                filtered_guesses = filtered_guesses.intersection(any_letter_answer_dict[answer][i])\n",
    "        for guess in filtered_guesses:\n",
    "            if check_fit(answer, guess, result):\n",
    "                possible_answers.add(answer)\n",
    "                break\n",
    "    return possible_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary mapping possible patterns given as responses to wordle guesses to possible words that \n",
    "# could've been the answer for that pattern\n",
    "def create_pattern_words_dict():\n",
    "    try:\n",
    "        #Read from file for words that fit each possible pattern\n",
    "        with open(\"saved_word_patterns\", \"rb\") as f:\n",
    "            pattern_words = pickle.load(f)\n",
    "    except:\n",
    "        #If file is missing or something, recreate it. Takes ~10 min\n",
    "        pos_letter_answer_dict, any_letter_answer_dict = create_useful_dicts()\n",
    "        #All sequences of 5 colored blocks\n",
    "        possible_patterns = product([0,1,2], repeat=5)\n",
    "        pattern_words = {}\n",
    "        for pattern in possible_patterns:\n",
    "            pattern_words[pattern] = result_answers_opt(list(pattern), answers, guesses, pos_letter_answer_dict, any_letter_answer_dict)\n",
    "        \n",
    "        #Dump to file to be read if needed later\n",
    "        with open(\"saved_word_patterns\", \"wb\") as f:\n",
    "            pickle.dump(pattern_words, f)\n",
    "    return pattern_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_answers(answers, pattern_words, results):\n",
    "    filtered_answers= set(answers)\n",
    "    for res in results:\n",
    "        oth = pattern_words[res]\n",
    "        filtered_answers = filtered_answers.intersection(oth)\n",
    "    return filtered_answers\n",
    "\n",
    "#Create all possible patterns for a guess for answer word. Check how well those can narrow it down\n",
    "def test_filter(answers, pattern_words, word):\n",
    "    results = set()\n",
    "    for guess in guesses:\n",
    "        results.add(tuple(score(word, guess)))\n",
    "    return filter_answers(answers, pattern_words, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('knack', ['shore', 'knack'])\n",
      "('maxim', ['share', 'maxim', 'laden'])\n",
      "('pygmy', ['elate', 'terse', 'saute', 'daily', 'surge', 'parse', 'beady', 'diary', 'tawny', 'pygmy', 'sauce'])\n",
      "('slyly', ['brain', 'slyly', 'saint', 'pried'])\n",
      "('skiff', ['stare', 'shard', 'loser', 'spiel', 'spied', 'swath', 'spelt', 'saint', 'skiff', 'sober', 'stall', 'stole'])\n",
      "('tight', ['posit', 'tight'])\n",
      "('amaze', ['amaze', 'slate'])\n"
     ]
    }
   ],
   "source": [
    "pattern_words = create_pattern_words_dict()\n",
    "#Little test, just for fun. See from 100 words how many wouldn't be able to be found\n",
    "for answer in random.sample(answers, 100):\n",
    "    b = list(test_filter(answers, pattern_words, answer))\n",
    "    if len(b) != 1 or b[0] != answer:\n",
    "        print(answer, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter search from https://towardsdatascience.com/searching-for-tweets-with-python-f659144b225f\n",
    "\n",
    "#define search twitter function\n",
    "def search_twitter(query, tweet_fields, bearer_token = BEARER_TOKEN, count = 10, end_time = -1):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    \n",
    "    endpoint_url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "    if end_time == -1:\n",
    "        url = \"{}?query={}&max_results={}&{}\".format(endpoint_url, query, count, tweet_fields)\n",
    "    else:\n",
    "        url=\"{}?query={}&max_results={}&end_time={}&{}\".format(endpoint_url, query, count, end_time, tweet_fields)\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "    print(response.status_code)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def get_twitter_response(wordle_num, num = 50, end_time = -1):\n",
    "    #search term\n",
    "    query = \"Wordle \"+str(wordle_num)\n",
    "    #twitter fields to be returned by api call\n",
    "    tweet_fields = \"tweet.fields=text,author_id,created_at\"\n",
    "    json_response = search_twitter(query, tweet_fields, BEARER_TOKEN, count=num, end_time=end_time)\n",
    "    \n",
    "    return json_response\n",
    "\n",
    "def produce_results(json_response):\n",
    "    results = set()\n",
    "    counted_results = Counter()\n",
    "    for response in json_response['data']:\n",
    "        text = response['text']\n",
    "        for line in text.split('\\n'):\n",
    "            if re.search(u'[^\\U0001f7e8|\\U0001f7e9|\\u2b1b|\\u2b1c]', line):\n",
    "                continue\n",
    "            try:\n",
    "                converted = line\\\n",
    "                    .replace(u'\\U0001f7e8', '1')\\\n",
    "                    .replace(u'\\U0001f7e9', '2')\\\n",
    "                    .replace(u'\\u2b1b', '0')\\\n",
    "                    .replace(u'\\u2b1c', '0')\n",
    "                tup = tuple([int(x) for x in list(converted)])\n",
    "                if len(tup) == 5: \n",
    "                    results.add(tup)\n",
    "                    counted_results.update([tup])\n",
    "            except:\n",
    "                print (line)\n",
    "                continue\n",
    "    return results, counted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_wordle(wordle_num, time_wait = 2, count = 20):\n",
    "    pattern_words = create_pattern_words_dict()\n",
    "    all_responses = []\n",
    "    \n",
    "    json_resp = get_twitter_response(wordle_num, num = count)\n",
    "    all_responses.append(json_resp)\n",
    "    earliest_time = json_resp['data'][-1]['created_at']\n",
    "    results, counted_results = produce_results(json_resp)\n",
    "    \n",
    "    filtered_answers = filter_answers(answers, pattern_words, results)\n",
    "    \n",
    "    while len(filtered_answers) > 1:\n",
    "        if len(filtered_answers) == 0:\n",
    "            print(\"Oops. Ran out of words....\")\n",
    "            break\n",
    "        \n",
    "        print(\"getting more tweets. still have\", len(filtered_answers), \"words left\")\n",
    "        time.sleep(time_wait) #Just so as to not overdo it\n",
    "        json_resp = get_twitter_response(wordle_num, end_time=earliest_time, num = count)\n",
    "        all_responses.append(json_resp)\n",
    "        earliest_time = json_resp['data'][-1]['created_at']\n",
    "        \n",
    "        #Update the results and counted results sets/counters\n",
    "        new_results, new_counted_results = produce_results(json_resp)\n",
    "        new_results = new_results.union(results)\n",
    "        new_counted_results.update(counted_results)\n",
    "        if len(new_results) == len(results): #Shouldn't just run forever. Stop here I guess\n",
    "            print(\"didn't find any new patterns, sorry\")\n",
    "            break\n",
    "        results = new_results\n",
    "        counted_results = new_counted_results\n",
    "        filtered_answers = filter_answers(answers, pattern_words, [x for x,i in new_counted_results.most_common() if i > 1])\n",
    "        \n",
    "    return  filtered_answers, all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "('getting more tweets. still have', 16, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 57, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 51, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 44, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 36, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 13, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 13, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 13, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 13, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 8, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 8, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 8, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 8, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 6, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 6, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 6, 'words left')\n",
      "200\n",
      "('getting more tweets. still have', 6, 'words left')\n",
      "200\n",
      "didn't find any new patterns, sorry\n"
     ]
    }
   ],
   "source": [
    "words, responses = answer_wordle(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bloke', 'crate', 'lease', 'saute', 'slate', 'slope'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few test to work out why it wasn't finding the words right. Looks like sometimes there are tweets that just don't seem possible for the quiz of the day. Possibly a mistake in making the text that gets shared on social media. Also possible that the search for \"Wordle xxx\" on twitter returns shares from other websites using the same patterns of blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_answer = 'bloke'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'text': u'Wordle 250 5/6\\n\\n\\u2b1b\\U0001f7e8\\u2b1b\\U0001f7e8\\u2b1b\\n\\u2b1b\\u2b1b\\u2b1b\\U0001f7e9\\U0001f7e8\\n\\u2b1b\\U0001f7e8\\U0001f7e8\\U0001f7e9\\U0001f7e8\\n\\u2b1b\\U0001f7e8\\U0001f7e9\\U0001f7e9\\u2b1b\\n\\U0001f7e9\\U0001f7e9\\U0001f7e9\\U0001f7e9\\U0001f7e9', u'created_at': u'2022-02-25T06:49:44.000Z', u'author_id': u'403138409', u'id': u'1497101488824352770'} Wordle 250 5/6\n",
      "\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛⬛⬛🟩🟨\n",
      "⬛🟨🟨🟩🟨\n",
      "⬛🟨🟩🟩⬛\n",
      "🟩🟩🟩🟩🟩 https://twitter.com/a/status/1497101488824352770\n",
      "{u'text': u'Wordle 250 4/6\\n\\n\\u2b1c\\u2b1c\\u2b1c\\u2b1c\\u2b1c\\n\\u2b1c\\U0001f7e8\\U0001f7e8\\u2b1c\\U0001f7e8\\n\\U0001f7e9\\U0001f7e8\\U0001f7e9\\u2b1c\\u2b1c\\n\\U0001f7e9\\U0001f7e9\\U0001f7e9\\U0001f7e9\\U0001f7e9', u'created_at': u'2022-02-25T06:22:04.000Z', u'author_id': u'45521586', u'id': u'1497094528498429952'} Wordle 250 4/6\n",
      "\n",
      "⬜⬜⬜⬜⬜\n",
      "⬜🟨🟨⬜🟨\n",
      "🟩🟨🟩⬜⬜\n",
      "🟩🟩🟩🟩🟩 https://twitter.com/a/status/1497094528498429952\n"
     ]
    }
   ],
   "source": [
    "for res in responses:\n",
    "    for i,r in enumerate(res ['data']):\n",
    "        if actual_answer not in filter_answers(answers, pattern_words, produce_results({'data':[r]})[0]):\n",
    "            print r, r['text'], 'https://twitter.com/a/status/' + str(r['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
